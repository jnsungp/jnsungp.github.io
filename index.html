<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Junsung Park</title>

    <meta name="author" content="Junsung Park">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
    <link href="https://fonts.googleapis.com/css2?family=Lato:wght@400;700&display=swap" rel="stylesheet">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin:auto;">
              <tbody>
                <tr>
                  <td style="padding:2.5%;width:63%;vertical-align:middle">
                    <p class="name" style="text-align:center;">Junsung Park</p>

                    <p>
                      I am an undergraduate student in the
                      <a href="https://ece.snu.ac.kr/en">Department of Electrical and Computer Engineering</a>
                      at <strong>Seoul National University (SNU)</strong>, pursuing a minor in Mechanical Engineering.
                    </p>
                    
                    <p>
                      Currently, I am a research intern at the 
                      <a href="https://scholar.google.com/citations?user=N0ZCT00AAAAJ&hl=en">Robot Learning Laboratory (RLLAB)</a>,
                      advised by Prof. <a href="https://scholar.google.com/citations?user=N0ZCT00AAAAJ&hl=en">Songhwai Oh</a>.
                    </p>

                    <p>
                      My research goal is to build <strong>generalizable robot autonomy</strong> capable of robust interaction in unstructured environments. 
                      I am particularly interested in <strong>Robot Learning</strong>, focusing on Vision–Language–Action (VLA) models, cross-embodiment transfer, and offline reinforcement learning.
                    </p>

                    <p style="text-align:center;">
                      <a href="mailto:night1115@snu.ac.kr">Email</a> &nbsp;/&nbsp;
                      <a href="data/JunsungPark_CV.pdf">CV</a> &nbsp;/&nbsp;
                      <a href="https://www.linkedin.com/in/junsung-park">LinkedIn</a> &nbsp;/&nbsp;
                      <a href="https://github.com/jnsungp">Github</a>
                    </p>
                  </td>

                  <td style="padding:2.5%;width:37%;max-width:37%">
                    <a href="images/JunsungPark.jpg">
                      <img src="images/JunsungPark.jpg"
                           style="width:100%;object-fit:cover;border-radius:50%;box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2);"
                           alt="profile photo">
                    </a>
                  </td>
                </tr>
              </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin:auto;">
              <tbody>
                <tr>
                  <td style="padding:16px;">
                    <h2>Research</h2>
                    <p>
                      I focus on leveraging multimodal sensing (RGB, depth, tactile) and foundation models to scale up robotic manipulation skills across different morphologies.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin:auto;">
              <tbody>
                <tr>
                  <td style="padding:16px;width:20%;vertical-align:middle">
                    <div style="width:100%; position: relative; overflow: hidden; border-radius:10px;">
                        <video 
                          src="images/g1_dataset.mp4" 
                          autoplay muted loop playsinline 
                          style="width:100%; display: block;">
                        </video>
                    </div>
                  </td>
                  <td style="padding:8px;width:80%;vertical-align:middle">
                    <a href="https://huggingface.co/jnsungp">
                      <span class="papertitle">Unitree G1 Multimodal Manipulation Dataset</span>
                    </a>
                    <br>
                    <strong>Junsung Park</strong>
                    <br>
                    <em>Open Source Project & Dataset</em>
                    <br>
                    <a href="https://huggingface.co/jnsungp">[Dataset]</a> /
                    <a href="https://github.com/jnsungp">[Code]</a>

                    <p>
                      Engineered a large-scale multimodal dataset generation pipeline for the <strong>Unitree G1 Humanoid</strong> by integrating MuJoCo, RoboCasa, and cuRobo.
                      The dataset features synchronized RGB-D, contact-state, 8D force–torque feedback, and proprioceptive data to facilitate the training of <strong>foundation robot policies</strong> in simulated environments.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin:auto;">
              <tbody>
                <tr>
                  <td style="padding:16px;width:20%;vertical-align:middle">
                    <img src="images/bicql-thumbnail.png"
                         style="width:100%;border-radius:10px;border:1px solid #EEE;"
                         alt="BiCQL thumbnail">
                  </td>
                  <td style="padding:8px;width:80%;vertical-align:middle">
                    <a href="#">
                      <span class="papertitle">
                        BiCQL-ML: A Bi-Level Conservative Q-Learning Framework for Maximum Likelihood IRL
                      </span>
                    </a>
                    <br>
                    <strong>Junsung Park</strong>, (Collaborators names if any)
                    <br>
                    <em>Preprint / Under Review</em>
                    <br>
                    <a href="#">[Paper (Coming Soon)]</a>

                    <p>
                      Proposed a <strong>policy-free offline Inverse Reinforcement Learning (IRL)</strong> framework that addresses reward ambiguity and distribution shift. 
                      By formulating a bi-level optimization problem that jointly learns a conservative Q-function and a reward function, BiCQL-ML improves robustness and expert-likeness in offline settings.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin:auto;">
              <tbody>
                <tr>
                  <td style="padding:16px;width:20%;vertical-align:middle">
                    <img src="images/g1-modality.png"
                         style="width:100%;border-radius:10px;border:1px solid #EEE;"
                         alt="G1 Modality">
                  </td>
                  <td style="padding:8px;width:80%;vertical-align:middle">
                    <a href="#">
                      <span class="papertitle">
                        Modality-Augmented Fine-Tuning of Foundation Robot Policies
                      </span>
                    </a>
                    <br>
                    <strong>Junsung Park</strong>
                    <br>
                    <em>In Preparation</em>
                    <br>
                    <p>
                      Investigating the efficacy of incorporating dense tactile and force feedback into diffusion-based policies.
                      This work focuses on <strong>cross-embodiment adaptation</strong>, specifically transferring manipulation skills to the Unitree G1 humanoid via modality-augmented fine-tuning.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>
            
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin:auto;">
                <tr>
                    <td style="padding:0px">
                        <br>
                        <p style="text-align:right;font-size:small;">
                            <a href="https://github.com/jonbarron/website">Template source</a>
                        </p>
                    </td>
                </tr>
            </table>

          </td>
        </tr>
      </tbody>
    </table>
  </body>
</html>
